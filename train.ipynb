{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd '/content/drive/My Drive/Colab Notebooks/yolov2'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKzebUnK63EZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from args import arg_parse\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "from dataset import VOCDataset\n",
        "from yolov2 import YOLOv2\n",
        "from utils import draw_boxes, get_detection_result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffWWBYUg65zZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parser = arg_parse()\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "# define and load YOLOv2\n",
        "net = YOLOv2(args)\n",
        "net.load_weight()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkTb4H-L8XNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train():\n",
        "\n",
        "    net.train()\n",
        "\n",
        "    # define optimizer\n",
        "    optimizer = optim.SGD(net.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.decay)\n",
        "\n",
        "    # create data batch generator\n",
        "    training_set = VOCDataset(\"../dataset/VOCdevkit/\", \"2012\", \"train\", image_size=net.IMAGE_W)\n",
        "    dataloader = DataLoader(training_set, shuffle= True, batch_size=net.BATCH_SIZE)\n",
        "    \n",
        "    N_ITERS_PER_EPOCH = len(dataloader) // net.BATCH_SIZE\n",
        "\n",
        "    writer = SummaryWriter()\n",
        "    writer.add_graph(net, torch.rand(4, 3, 416, 416))\n",
        "\n",
        "    for epoch in range(args.epoch):\n",
        "        \n",
        "        for batch_idx, (images, labels) in enumerate(dataloader):\n",
        "\n",
        "            print(\"\")\n",
        "            print(\"========== Epoch: {}, step: {} ==========\".format(epoch, batch_idx))\n",
        "\n",
        "            images, labels = Variable(images, requires_grad = True), labels\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = net.forward(images)\n",
        "\n",
        "            loss, loss_coord, loss_conf, loss_cls = net.loss(output, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            loss, loss_coord, loss_conf, loss_cls = [l.item() for l in [loss, loss_coord, loss_conf, loss_cls]]\n",
        "\n",
        "            ### logs to tensorboard\n",
        "            writer.add_scalar('Train/Total_loss', loss, epoch * N_ITERS_PER_EPOCH + batch_idx)\n",
        "            writer.add_scalar('Train/Coordination_loss', loss_coord, epoch * N_ITERS_PER_EPOCH + batch_idx)\n",
        "            writer.add_scalar('Train/Confidence_loss', loss_conf, epoch * N_ITERS_PER_EPOCH + batch_idx)\n",
        "            writer.add_scalar('Train/Class_loss', loss_cls, epoch * N_ITERS_PER_EPOCH + batch_idx)\n",
        "\n",
        "            ### log to console\n",
        "            print('- Train/Total_loss: ', loss)\n",
        "            print('- Train/Coordination_loss: ', loss_coord)\n",
        "            print('- Train/Confidence_loss: ', loss_conf)\n",
        "            print('- Train/Class_loss: ', loss_cls)\n",
        "\n",
        "            if batch_idx % 10 == 0:\n",
        "                boxes = get_detection_result(output, net.ANCHORS, net.CLASS, conf_thres=.8, nms_thres=0.4)\n",
        "\n",
        "                # draw detected boxes and save sample\n",
        "                im = images[0].data.numpy().astype('uint8')\n",
        "                im = im.transpose(1,2,0)\n",
        "                im = im.copy()\n",
        "                color_red = (0, 0, 255)\n",
        "                color_green = (0, 255, 0)\n",
        "                im = draw_boxes(im, labels[0], net.LABELS, color=color_green)\n",
        "                im = draw_boxes(im, boxes[0], net.LABELS, color = color_red)\n",
        "\n",
        "                file_path = os.path.join(args.output, \"result_epoch_{}_iter_{}.jpg\".format(epoch, batch_idx))\n",
        "                cv2.imwrite(file_path, im)\n",
        "\n",
        "    writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQ4DCNPJO1qo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}